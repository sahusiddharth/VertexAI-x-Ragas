{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "\n",
    "evaluator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4o-mini\"))\n",
    "evaluator_embeddings = LangchainEmbeddingsWrapper(OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datasets import load_dataset\n",
    "from ragas import evaluate, EvaluationDataset\n",
    "\n",
    "\n",
    "dataset = load_dataset(\"explodinggradients/ELI5\",split=\"test\")\n",
    "eval_dataset = EvaluationDataset.from_hf_dataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.metrics import SimpleCriteriaScore, RubricsScore\n",
    "\n",
    "simple_criteria = SimpleCriteriaScore(\n",
    "    name=\"Answer Strength Rating\", \n",
    "    definition=\"A metric that evaluates the quality of an answer based on its strengths and weaknesses, rating it as Excellent (4), Acceptable (3), Could be Improved (2), or Bad (1).\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempt 2\n",
    "\n",
    "using dataset from \n",
    "- https://github.com/McGill-NLP/feedbackqa\n",
    "- https://huggingface.co/datasets/McGill-NLP/feedbackQA (test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What are my options if I can not support mysel...</td>\n",
       "      <td>You should only apply for this visa is you are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I was a working Holiday Maker but lost my job;...</td>\n",
       "      <td>You should only apply for this visa is you are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Is it practical to expect children to practice...</td>\n",
       "      <td>If your child is sick, they must not go to sch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Do I have to continue making gym membership pa...</td>\n",
       "      <td>\\nMembership ‘freeze’ or ‘holding’ fees may be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Can I keep on working while waiting to see if ...</td>\n",
       "      <td>In response to the current COVID-19 pandemic, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Can I continue to work while I am waiting for ...</td>\n",
       "      <td>The COVID-19 Pandemic event visa can only be g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Can I get a refund for the tickets I bought be...</td>\n",
       "      <td>\\nIf you no longer wish to attend an event due...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Where and how will the Economic Support Paymen...</td>\n",
       "      <td>If you are in receipt of an eligible income su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>what ways can I apply for a temporal activity ...</td>\n",
       "      <td>Under recently announced measures, New Zealand...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>If I am in Australia on temporary visa and hav...</td>\n",
       "      <td>Temporary visa holders, including bridging vis...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          user_input  \\\n",
       "0  What are my options if I can not support mysel...   \n",
       "1  I was a working Holiday Maker but lost my job;...   \n",
       "2  Is it practical to expect children to practice...   \n",
       "3  Do I have to continue making gym membership pa...   \n",
       "4  Can I keep on working while waiting to see if ...   \n",
       "5  Can I continue to work while I am waiting for ...   \n",
       "6  Can I get a refund for the tickets I bought be...   \n",
       "7  Where and how will the Economic Support Paymen...   \n",
       "8  what ways can I apply for a temporal activity ...   \n",
       "9  If I am in Australia on temporary visa and hav...   \n",
       "\n",
       "                                            response  \n",
       "0  You should only apply for this visa is you are...  \n",
       "1  You should only apply for this visa is you are...  \n",
       "2  If your child is sick, they must not go to sch...  \n",
       "3  \\nMembership ‘freeze’ or ‘holding’ fees may be...  \n",
       "4  In response to the current COVID-19 pandemic, ...  \n",
       "5  The COVID-19 Pandemic event visa can only be g...  \n",
       "6  \\nIf you no longer wish to attend an event due...  \n",
       "7  If you are in receipt of an eligible income su...  \n",
       "8  Under recently announced measures, New Zealand...  \n",
       "9  Temporary visa holders, including bridging vis...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ragas.config import InstructionConfig,DemonstrationConfig\n",
    "import pandas as pd\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "from ragas.metrics import RubricsScore\n",
    "from ragas import evaluate\n",
    "\n",
    "llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4o-mini\"))\n",
    "embeddings = LangchainEmbeddingsWrapper(OpenAIEmbeddings())\n",
    "\n",
    "\n",
    "demo_config = DemonstrationConfig(embedding = embeddings)\n",
    "inst_config = InstructionConfig(llm=llm)\n",
    "\n",
    "df = pd.read_json(\"feedback_test.json\")[:10]\n",
    "\n",
    "from ragas.dataset_schema import EvaluationDataset, SingleTurnSample\n",
    "\n",
    "samples = []\n",
    "for i, row in df.iterrows():\n",
    "\tsample = SingleTurnSample(\n",
    "\t\tuser_input=row[\"question\"],\n",
    "\t\tresponse=row[\"passage\"][\"reference\"][\"section_content\"],\n",
    "\t)\n",
    "\tsamples.append(sample)\n",
    "\n",
    "\n",
    "ragas_dataset = EvaluationDataset(samples=samples)\n",
    "\n",
    "ragas_dataset.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def read_from_json(path):\n",
    "\twith open(path, 'r') as file:\n",
    "\t\tdata = json.load(file)\n",
    "\t\tfor i in data[\"answer_strength_rating\"]:\n",
    "\t\t\tprint(i[\"metric_output\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>human 1</th>\n",
       "      <th>human 2</th>\n",
       "      <th>human 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   human 1  human 2  human 3\n",
       "0        1        1        1\n",
       "1        1        1        1\n",
       "2        1        2        1\n",
       "3        4        2        4\n",
       "4        1        2        4\n",
       "5        1        1        1\n",
       "6        4        3        4\n",
       "7        3        4        2\n",
       "8        1        1        1\n",
       "9        1        1        1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_scores = []\n",
    "\n",
    "category_to_number = {\n",
    "    'Excellent': 4,\n",
    "    'Acceptable': 3,\n",
    "    'Could be Improved': 2,\n",
    "    'Bad': 1\n",
    "}\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    score = {\n",
    "        \"human 1\": category_to_number[row[\"rating\"][0]],\n",
    "\t\t\"human 2\": category_to_number[row[\"rating\"][1]],\n",
    "\t\t\"human 3\": category_to_number[row[\"rating\"][2]],\n",
    "\t}\n",
    "    human_scores.append(score)\n",
    "    \n",
    "human_judges = pd.DataFrame(human_scores)\n",
    "human_judges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Human1 allignment test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "h1_answer_strength_rating = RubricsScore(\n",
    "    name=\"answer_strength_rating\",\n",
    "    rubrics={\n",
    "        \"4\": \"Answer is excellent, highly relevant, and fully addresses the question with clarity and detail.\",\n",
    "        \"3\": \"Answer is acceptable, mostly relevant but could be more comprehensive or refined.\",\n",
    "        \"2\": \"Answer could be improved, as it lacks detail, may have minor inaccuracies, or is somewhat unclear.\",\n",
    "        \"1\": \"Answer is bad, irrelevant, misleading, or lacks useful content.\"\n",
    "    },\n",
    "    llm=evaluator_llm,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>human 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   human 1\n",
       "0        1\n",
       "1        1\n",
       "2        1\n",
       "3        4\n",
       "4        1\n",
       "5        1\n",
       "6        4\n",
       "7        3\n",
       "8        1\n",
       "9        1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_judges[[\"human 1\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "069910787b2f4f39ba6ac98b397d1d90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results uploaded! View at https://app.ragas.io/dashboard/alignment/evaluation/7126d2cc-4bf1-47c4-bb93-36ea681f6e77\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://app.ragas.io/dashboard/alignment/evaluation/7126d2cc-4bf1-47c4-bb93-36ea681f6e77'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h11_results = evaluate(dataset=ragas_dataset, metrics=[h1_answer_strength_rating])\n",
    "h11_results.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n",
      "2\n",
      "4\n",
      "2\n",
      "1\n",
      "4\n",
      "3\n",
      "1\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "read_from_json(\"h1_annotated.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2\n",
       "1    2\n",
       "2    2\n",
       "3    4\n",
       "4    2\n",
       "5    1\n",
       "6    4\n",
       "7    3\n",
       "8    1\n",
       "9    3\n",
       "Name: answer_strength_rating, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h11_results.to_pandas()[\"answer_strength_rating\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "h1_answer_strength_rating.train(path=\"h1_annotated.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ff29f8ce9464c4fadce4be8a86ac659",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    2\n",
       "1    2\n",
       "2    2\n",
       "3    4\n",
       "4    2\n",
       "5    1\n",
       "6    4\n",
       "7    3\n",
       "8    1\n",
       "9    3\n",
       "Name: answer_strength_rating, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h12_results = evaluate(dataset=ragas_dataset, metrics=[h1_answer_strength_rating])\n",
    "h12_results.to_pandas()[\"answer_strength_rating\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "original = human_judges[\"human 1\"]\n",
    "rh11 = h11_results.to_pandas()[\"answer_strength_rating\"]\n",
    "rh12 = h12_results.to_pandas()[\"answer_strength_rating\"]\n",
    "\n",
    "r1 = cohen_kappa_score(y1=original, y2=rh11)\n",
    "r2 = cohen_kappa_score(y1=original, y2=rh12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.375\n",
      "0.375\n"
     ]
    }
   ],
   "source": [
    "print(r1)\n",
    "print(r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Human2 allignment test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2_answer_strength_rating = RubricsScore(\n",
    "    name=\"answer_strength_rating\",\n",
    "    rubrics={\n",
    "        \"4\": \"Answer is excellent, highly relevant, and fully addresses the question with clarity and detail.\",\n",
    "        \"3\": \"Answer is acceptable, mostly relevant but could be more comprehensive or refined.\",\n",
    "        \"2\": \"Answer could be improved, as it lacks detail, may have minor inaccuracies, or is somewhat unclear.\",\n",
    "        \"1\": \"Answer is bad, irrelevant, misleading, or lacks useful content.\"\n",
    "    },\n",
    "    llm=evaluator_llm,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>human 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   human 2\n",
       "0        1\n",
       "1        1\n",
       "2        2\n",
       "3        2\n",
       "4        2\n",
       "5        1\n",
       "6        3\n",
       "7        4\n",
       "8        1\n",
       "9        1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_judges[[\"human 2\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6a0815f20684f49b64c498e42d749f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results uploaded! View at https://app.ragas.io/dashboard/alignment/evaluation/4881a866-2319-4f72-9ef3-e2c84fde3847\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://app.ragas.io/dashboard/alignment/evaluation/4881a866-2319-4f72-9ef3-e2c84fde3847'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h21_results = evaluate(dataset=ragas_dataset, metrics=[h2_answer_strength_rating])\n",
    "h21_results.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n",
      "2\n",
      "4\n",
      "2\n",
      "1\n",
      "4\n",
      "3\n",
      "1\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "read_from_json(\"h2_annotated.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2\n",
       "1    2\n",
       "2    2\n",
       "3    4\n",
       "4    2\n",
       "5    1\n",
       "6    4\n",
       "7    3\n",
       "8    1\n",
       "9    3\n",
       "Name: answer_strength_rating, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h21_results.to_pandas()[\"answer_strength_rating\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2_answer_strength_rating.train(path=\"h2_annotated.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d78710e191624ac28a015f3b0962a969",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    2\n",
       "1    2\n",
       "2    2\n",
       "3    4\n",
       "4    2\n",
       "5    1\n",
       "6    4\n",
       "7    3\n",
       "8    1\n",
       "9    3\n",
       "Name: answer_strength_rating, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h22_results = evaluate(dataset=ragas_dataset, metrics=[h2_answer_strength_rating])\n",
    "h22_results.to_pandas()[\"answer_strength_rating\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "original = human_judges[\"human 2\"]\n",
    "rh21 = h21_results.to_pandas()[\"answer_strength_rating\"]\n",
    "rh22 = h22_results.to_pandas()[\"answer_strength_rating\"]\n",
    "\n",
    "r1 = cohen_kappa_score(y1=original, y2=rh21)\n",
    "r2 = cohen_kappa_score(y1=original, y2=rh22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18918918918918926\n",
      "0.18918918918918926\n"
     ]
    }
   ],
   "source": [
    "print(r1)\n",
    "print(r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Human3 allignment test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "h3_answer_strength_rating = RubricsScore(\n",
    "    name=\"answer_strength_rating\",\n",
    "    rubrics={\n",
    "        \"4\": \"Answer is excellent, highly relevant, and fully addresses the question with clarity and detail.\",\n",
    "        \"3\": \"Answer is acceptable, mostly relevant but could be more comprehensive or refined.\",\n",
    "        \"2\": \"Answer could be improved, as it lacks detail, may have minor inaccuracies, or is somewhat unclear.\",\n",
    "        \"1\": \"Answer is bad, irrelevant, misleading, or lacks useful content.\"\n",
    "    },\n",
    "    llm=evaluator_llm,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>human 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   human 3\n",
       "0        1\n",
       "1        1\n",
       "2        1\n",
       "3        4\n",
       "4        4\n",
       "5        1\n",
       "6        4\n",
       "7        2\n",
       "8        1\n",
       "9        1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_judges[[\"human 3\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9129a6e4cf3243fdbe1bc733df5b19f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results uploaded! View at https://app.ragas.io/dashboard/alignment/evaluation/4e3c4fdd-7ec5-4c76-a590-81d2e1e738e3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://app.ragas.io/dashboard/alignment/evaluation/4e3c4fdd-7ec5-4c76-a590-81d2e1e738e3'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h31_results = evaluate(dataset=ragas_dataset, metrics=[h3_answer_strength_rating])\n",
    "h31_results.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n",
      "2\n",
      "4\n",
      "2\n",
      "1\n",
      "4\n",
      "3\n",
      "1\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "read_from_json(\"h3_annotated.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2\n",
       "1    2\n",
       "2    2\n",
       "3    4\n",
       "4    2\n",
       "5    1\n",
       "6    4\n",
       "7    3\n",
       "8    1\n",
       "9    3\n",
       "Name: answer_strength_rating, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h31_results.to_pandas()[\"answer_strength_rating\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "h3_answer_strength_rating.train(path=\"h3_annotated.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a4ad3d816f04f5a8fe803a1b12a8865",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    2\n",
       "1    2\n",
       "2    2\n",
       "3    4\n",
       "4    2\n",
       "5    1\n",
       "6    4\n",
       "7    3\n",
       "8    1\n",
       "9    3\n",
       "Name: answer_strength_rating, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h32_results = evaluate(dataset=ragas_dataset, metrics=[h3_answer_strength_rating])\n",
    "h32_results.to_pandas()[\"answer_strength_rating\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "original = human_judges[\"human 3\"]\n",
    "rh31 = h31_results.to_pandas()[\"answer_strength_rating\"]\n",
    "rh32 = h32_results.to_pandas()[\"answer_strength_rating\"]\n",
    "\n",
    "r1 = cohen_kappa_score(y1=original, y2=rh31)\n",
    "r2 = cohen_kappa_score(y1=original, y2=rh32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23076923076923073\n",
      "0.23076923076923073\n"
     ]
    }
   ],
   "source": [
    "print(r1)\n",
    "print(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
